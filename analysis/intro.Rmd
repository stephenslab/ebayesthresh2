---
title: "Introduction to ebayesthresh2"
author: "Matthew Stephens"
date: 2017-02-27
output: html_document
---

```{r read-chunk, include=FALSE, cache=FALSE}
knitr::read_chunk("chunks.R")
```

```{r knitr-opts-chunk, include=FALSE}
```

**Last updated:** `r Sys.Date()`

**Code version:** `r workflowr::extract_commit(".", 1)$sha1`


## EbayesThresh

The `EbayesThresh` package implements an Empirical Bayes approach to shrinkage for the normal means problem. There are various options, but the one I am interested in is the Laplace option.
Specifically, with this option, the function `ebayesthresh` solves the following "normal means" problem:
Data $x_1,\dots,x_n$ are assumed to be from
$$x_j | \mu_j \sim N(\mu_j,s^2)$$
where
$$\mu_j \sim \pi_0 \delta_0 + (1-\pi_0) \text{DExp}(a)$$
where $\text{Dexp}(a)$ denotes the double exponential distribution with parameter $a$.

The Empirical Bayes approach estimates both $\pi_0$ and $a$ by maximum likelihood
applied to the data $x_1,\dots,x_n$. Then it estimates each $\mu_j$ by its posterior mean (or 
posterior median is also an option).

Here is an example. (Note that setting `a=NA` indicates that `a` is to be estimated.)
```{r}
set.seed(1)
s = 1 # standard error
mu = rnorm(100)
x = mu + rnorm(100,0,s)
muhat.ebt = EbayesThresh::ebayesthresh(x,"laplace",a=NA,sdev=s,threshrule="mean") 
plot(mu,muhat.ebt)
mean((mu-x)^2)
mean((mu-muhat.ebt)^2)
```

And here is the same idea in `ashr` package:
```{r}
library("ashr")
x.ash = ash(x,s,method="shrink")
plot(mu,get_pm(x.ash))
mean((mu-get_pm(x.ash))^2)
```

You can see both methods are effective at reducing the Mean Squared Error compared with
the observations $x$. This is the benefit of "shrinkage".

Note that although the mean squared errors are almost identical, the actual results are different:
```{r}
plot(get_pm(x.ash),muhat.ebt,xlab="ash estimate", ylab="ebayesthresh estimate",xlim=c(-1.5,1.5),ylim=c(-1.5,1.5))
abline(a=0,b=1)
```

# Issues

There are 2 issues to investigate. The first is more software related; the second involves more statistical work as well as implementation.

## Problem 1: ebayesthresh crashes when the signal is very large

Here is an example where the mu are very large. What should happen is that a is estimated to be big, and very little shrinkage is performed. But it crashes:
```{r}
  set.seed(1)
  mu = rnorm(100,0,20)
  x = mu + rnorm(100,0,1)
  res=try(EbayesThresh::ebayesthresh(x,"laplace",a=NA,sdev=1,threshrule="mean"))
  print(res) #note i have to put it into the try() phrase to avoid my Rmd file crashing....
```



## Issue 2: ebayesthresh does not allow for error variances to vary

It is common to have non-homogenous variances:
$$x_j | \mu_j \sim N(\mu_j,s_j^2)$$

Can you modify ebayesthresh to allow for this? It seems it should not be too hard in principle,
but the details need to be worked out.


## Issue 3 (bonus)

Ok, so I said there were two issues, but if those two don't take very long, here is another thought.
The `EbayesThresh` package provides a nice interface to wavelet shrinkage using the
`ebayesthresh.wavelet` function which interfaces with the `wavethresh` package. It would be
nice to provide a similar function for `ashr`, that simply replaces `ebayesthresh` shrinkage with
`ashr` shrinkage.

## Session Information

```{r session-info}
```
